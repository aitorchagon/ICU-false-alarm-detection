{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### %load_ext autoreload\n\n#!pip install --upgrade scipy #actualizamos scipy para que cargue el módulo de señales\nimport os\nimport numpy as np\nimport scipy as sc\nfrom scipy import signal\nimport matplotlib.pyplot as plt\n\nimport numpy as np \nimport pandas as pd\n\n%matplotlib inline\nfrom scipy.io import loadmat\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import display, clear_output\n\n\n\nimport os\n\n!pip install biosppy\n!pip install pyhrv\n!pip install neurokit2\n!pip install hrv\n!pip install heartpy\n!pip install neurokit\n#ya vendría instalado spectrum\n\nimport heartpy\nimport biosppy\nimport neurokit2 as nk\nimport hrv\nimport pyhrv","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Obtenemos todas las señales. Apartado de preprocesado.\n#Tenemos 550 señales de training y 250 señales de test.\n#Se me ocurre a priori, tendría que comprobarlo, hay un algoritmo en MATLAB (rdmat)\n#que también lo saca si no funciona algo parecido a esto.\n#Iteramos sobre nombres de archivos para iterar después sobre señales\npath = '/kaggle/input/physiological-signals-processing-challenge-2021/data_challenge/training/'\n\nlista_nombres = []\nfor i in range(551): #Añado un 1 para que me imprima las 550, dado que Python empieza por el 0.\n    pat_filename = '{}.hea'.format(i)\n    if pat_filename == '0.hea': #Este archivo no existe pero Python se lo inventa\n        pass\n    else:\n        lista_nombres.append(pat_filename)\nlista_señales = []\nfor elem in lista_nombres:\n    pat = loadmat(os.path.join(path, elem[:-4] + '.mat'))     #el -4 es porque cubre exactamente\n    #el nombre del archivo hasta el inicio sin contar el punto\n    lista_señales.append(pat)\n#Hacemos el resampleo a 125 Hz, que tengo que mirar cómo se hace.\nfor elem in lista_señales:\n    elem = sc.signal.resample(elem['val'], 125)\n#¿Hace falta representar las señales?\n#Me interesa representar como mucho los últimos 20 segundos de un ejemplo(paciente 73).\nt = np.arange(0, 75000)/125\nplt.figure()\nplt.subplot(221)\nplt.plot(t, lista_señales[1]['val'][0,:75000])\nplt.title('Derivación II')\nplt.xlim(0, 50)\nplt.subplot(222)\nplt.plot(t, lista_señales[1]['val'][1,:75000])\nplt.title('Derivación V')\nplt.xlim(0, 50)\nplt.subplot(223)\nplt.plot(t, lista_señales[1]['val'][2, :75000])\nplt.title('PLETH')\nplt.xlim(0, 50)\nplt.subplot(224)\nplt.plot(t, lista_señales[1]['val'][3, :75000])\nplt.title('ABP')\nplt.xlim(0, 50)\n#Vale, ya he entendido esto. El valor 0 en ese índice corresponde a la derivación II, \n#el valor 1 a la 5, el valor 2 a PLETH y el valor 3 a ABP. \n#Me queda por entender el otro valor :75000, supongo que es el número de muestras?¿ Ni idea.\n\n#Nos dan igual las etiquetas, luego veo si las quito. Las etiquetas son II, V, PLETH, ABP:\n#para los dos canales de ECG, el canal que mide la saturación oxígeno arterial por cada latido\n# (oximetría) y el canal de la presión arterial.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Aplicamos filtro pasobajo en 50 Hz para eliminar la tensión de línea de corriente.\n#Aplicamos un notch IIR, la mayoría de la literatura utiliza este orden para filtrado ruido 50Hz\nb, a= sc.signal.iirnotch(38, fs = 125, Q = 30)\n#Aplicamos un filtro pasobanda 0.5-40Hz para quitar el baseline wander.\nc = sc.signal.firwin(64, [0.5, 40], pass_zero = False, fs=125, window='hamming')\n#De esta forma también nos quitamos el ruido de EMG a priori. Ese filtro se usa \n#constantemente en todos los papers consultados\n#Eliminamos valores nulos NaN\nlista_filtrada_II = []\nlista_filtrada_V = []\nlista_filtrada_ABP = []\nlista_filtrada_PLETH = []\nfor i in range (551):\n    try:#eliminamos tendencia lineal\n        elem1 = sc.signal.filtfilt(b, a, lista_señales[i]['val'][0, :75000]) \n        elem1 = sc.signal.filtfilt(c, 1, elem1)\n        elem1[np.isnan(elem1)] = 0.00001\n        elem1 = sc.signal.detrend(elem1)#eliminamos tendencia lineal\n        elem1 = heartpy.enhance_peaks(elem1, iterations = 2)#mejorar picos\n        lista_filtrada_II.append(elem1)\n        elem2 = sc.signal.filtfilt(b, a, lista_señales[i]['val'][1, :75000])\n        elem2 = sc.signal.filtfilt(c, 1, elem2)\n        elem2[np.isnan(elem2)] = 0.00001\n        elem2 = sc.signal.detrend(elem2)#eliminamos tendencia lineal\n        elem2 = heartpy.enhance_peaks(elem2, iterations = 2)#mejorar picos\n        lista_filtrada_V.append(elem2)\n        elem3 = sc.signal.filtfilt(b, a, lista_señales[i]['val'][2, :75000])\n        elem3 = sc.signal.filtfilt(c,1, elem3)\n        elem3[np.isnan(elem3)] = 0.00001\n        elem3 = sc.signal.detrend(elem3)#eliminamos tendencia lineal\n        elem3 = heartpy.enhance_peaks(elem3, iterations = 2)#mejorar picos \n        lista_filtrada_PLETH.append(elem3)\n        elem4 = sc.signal.filtfilt(b, a, lista_señales[i]['val'][3, :75000])\n        elem4 = sc.signal.filtfilt(c, 1, elem4)\n        elem4[np.isnan(elem4)] = 0.00001\n        elem4 = sc.signal.detrend(elem4)#eliminamos tendencia lineal\n        elem4 = heartpy.enhance_peaks(elem4, iterations = 2)#mejorar picos y evita clippeo\n        elem4 = lista_filtrada_ABP.append(elem4)\n    except IndexError:\n        continue\n    #filtramos las señales. El IndexError aparece porque no siempre hay PLETH o ABP\n    #para cada uno de los pacientes, y porque no hay paciente 0. Por ello, simplemente \n    #pasamos de ello y seguimos ejecutando el bucle for.\n    #Tras representar las señales, no me queda muy claro\n    # que haya cambiado algo. Quizás ya se quitó ese ruido \n    # con anterioridad.\n\nt = np.arange(0, 75000)/125\nplt.figure()\nplt.title('Señales filtradas')\nplt.subplot(221)\nplt.plot(t, lista_filtrada_II[1])\nplt.title('Derivación II')\nplt.xlim(0, 50)\nplt.subplot(222)\nplt.plot(t, lista_filtrada_V[1])\nplt.title('Derivación V')\nplt.xlim(0, 50)\nplt.subplot(223)\nplt.plot(t, lista_filtrada_PLETH[1])\nplt.title('PLETH')\nplt.xlim(0, 50)\nplt.subplot(224)\nplt.plot(t, lista_filtrada_ABP[1])\nplt.title('ABP')\nplt.xlim(0, 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Aquí empezamos con el bloque de adquisición de características. Las características \n#que vamos a obtener son:\n#índice de pureza espectral\n#calidad de pleth y abp\n#media HR y decrecimiento PLETH Y ABP (OSc-ANFc-W)\n#maximo de HR intervals en ECG (AMM)\n#---------------------------------------------- Linear Discriminant Analysis/ECG--><3.5 Asistolia\n#media y mediana HR PLETH Y ABP (OSc-ANFc-W)\n#minimo HR en 5 latidos consecutivos (AMM)\n#----------------------------------------------media y mediana > 54bpm/ECG-->>40bpm\n#HR máximo averaged en ventanas de 3 segundos (OSc-ANFc-W) PLETH-ABP ---> <90bpm\n#HR mínimo averaged en ventanas de 3 segundos (OSc-ANFc-W) PLETH-ABP----> >60bpm\n#En ECG igual con SPI (uno averaged y el otro incremento máximo) ---> max(SPI) <0.25 & and (max(SPI) <0.36\n#----------------------------------------------------------------------max(SPI increase <0.012 and (max(SPI) <0.36 & max(SPI increase) <0.2\n#--------------------------------------------------\n#max averaged SPI en ventanas de 3 segundos <0.63","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Obtenemos los picos R de las señales ECG y los intervalos RR\nrpeaks_II = []\nproperties_II = []\nrpeaks_V= []\nproperties_V = []\nrr_interval_V = []\nrr_interval_II = []\nfor i in range(len(lista_filtrada_V)):\n    rpeaksV, _ = sc.signal.find_peaks(lista_filtrada_V[i], distance = 150)\n    rpeaksV = biosppy.signals.ecg.correct_rpeaks(lista_filtrada_V[i], rpeaks = rpeaksV, sampling_rate = 125, tol = 0.04)\n    rr_intervalV = np.diff(rpeaksV)/125 * 1000\n    rpeaks_V.append(rpeaksV['rpeaks'])\n    rr_interval_V.append(rr_intervalV)\nfor i in range(len(lista_filtrada_II)):\n    rpeaksII, _ = sc.signal.find_peaks(lista_filtrada_II[i], distance = 150)\n    rpeaksII = biosppy.signals.ecg.correct_rpeaks(lista_filtrada_II[i], rpeaks = rpeaksII, sampling_rate = 125, tol = 0.04)\n    rpeaks_II.append(rpeaksII['rpeaks'])\n    rr_intervalII = np.diff(rpeaksII)/125 * 1000\n    rr_interval_II.append(rr_intervalII)\nfor i in range(len(lista_filtrada_V)):\n    rpeaksV, propertiesV = sc.signal.find_peaks(lista_filtrada_V[i], distance = 150, prominence = 1, width = 20)\n    properties_V.append(propertiesV[\"width_heights\"])\n    properties_V.append(propertiesV[\"prominences\"])\nfor i in range(len(lista_filtrada_II)):\n    rpeaksII, propertiesII = sc.signal.find_peaks(lista_filtrada_II[i], distance = 150, prominence = 1, width = 20)\n    properties_II.append(propertiesII[\"width_heights\"])\n    properties_II.append(propertiesII[\"prominences\"])\n#Detección de arritmias, en este caso fibrilación ventricular\n#rpeaksV, propertiesV = sc.signal.find_peaks(lista_filtrada_V[40], distance = 150, prominence = 1, width = 20)\n#anchura_pico = propertiesV['width_heights'] #te devuelve el ancho del pico\n#importante para arritmias por ejemplo donde, al haber más latidos, el pico R es más estrecho\n#prominencia = propertiesV['prominences'] #te devuelve cómo de alto es el pico\n#en relación con la línea de base.\n#Las podemos meter juntas o por separado, ver cómo funciona mejor.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Estadísticas principales: media, mediana, amplitud máxima, cuasivarianza, \n#desviación estándar, desviación absoluta, kurtosis, skewness\nmediaV = []\nmedianaV = []\namplitudmaxV = [] \ncuasivaV = []\nstdV = []\nstdabsV = [] \nkurtV = []\nskewV = []\nmediaII = [] \nmedianaII = []\namplitudmaxII = [] \ncuasivaII = []\nstdII = []\nstdabsII = [] \nkurtII = []\nskewII = []\nmediaPLETH = [] \nmedianaPLETH = []\namplitudmaxPLETH = [] \ncuasivaPLETH = []\nstdPLETH = []\nstdabsPLETH = [] \nkurtPLETH = []\nskewPLETH = []\nfor i in range(len(lista_filtrada_V)):\n    a = biosppy.signals.tools.signal_stats(lista_filtrada_V[i])\n    mediaV.append(a[0])\n    medianaV.append(a[1])\n    amplitudmaxV.append(a[2])\n    cuasivaV.append(a[3])\n    stdV.append(a[4])\n    stdabsV.append(a[5])\n    kurtV.append(a[6])\n    skewV.append(a[7])\nfor i in range(len(lista_filtrada_II)):\n    b = biosppy.signals.tools.signal_stats(lista_filtrada_II[i])\n    mediaII.append(b[0])\n    medianaII.append(b[1])\n    amplitudmaxII.append(b[2])\n    cuasivaII.append(b[3])\n    stdII.append(b[4])\n    stdabsII.append(b[5])\n    kurtII.append(b[6])\n    skewII.append(b[7])\nfor i in range(len(lista_filtrada_PLETH)):\n    c = biosppy.signals.tools.signal_stats(lista_filtrada_PLETH[i])\n    mediaPLETH.append(c[0])\n    medianaPLETH.append(c[1])\n    amplitudmaxPLETH.append(c[2])\n    cuasivaPLETH.append(c[3])\n    stdPLETH.append(c[4])\n    stdabsPLETH.append(c[5])\n    kurtPLETH.append(c[6])\n    skewPLETH.append(c[7])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculamos la autocorrelación\nautocorV = []\nautocorII = []\nautocorPLETH = []\nautocorABP = []\nfor i in range(len(lista_filtrada_V)):\n    autocor_V = np.correlate(lista_filtrada_V[i], lista_filtrada_V[i])\n    autocorV.append(autocor_V)\nfor i in range(len(lista_filtrada_II)):\n    autocor_II = np.correlate(lista_filtrada_II[i], lista_filtrada_II[i])\n    autocorII.append(autocor_II)\nfor i in range(len(lista_filtrada_PLETH)):\n    autocor_PLETH = np.correlate(lista_filtrada_PLETH[i], lista_filtrada_PLETH[i])\n    autocorPLETH.append(autocor_PLETH)\nfor i in range(len(lista_filtrada_ABP)):\n    autocor_ABP = np.correlate(lista_filtrada_ABP[i], lista_filtrada_ABP[i])\n    autocorABP.append(autocor_ABP)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Obtenemos ciertas características del PLETH. \n#De momento, no obtenemos características concretas de ABP.\npicos_sistolicos = []\nfor i in range(len(lista_filtrada_PLETH)):\n    try: #Calculamos las muestras donde se encuentran los picos sistólicos\n        sistolic_peaks = nk.ppg_findpeaks(lista_filtrada_PLETH[i], sampling_rate = 125)  \n        picos_sistolicos.append(sistolic_peaks['PPG_Peaks'][0])\n        \n    except IndexError: #Probablemente salte por el mismo motivo que antes\n        #por no haber suficientes latidos (habrá una bradicardia)\n        #Salta en 4, 64, 71, 289, 336 y 434.\n        picos_sistolicos.append(0)\n#Calculamos la tasa cardiaca en PLETH\nheart_rate_PLETH = []\nfor i in range(len(picos_sistolicos)):\n    tasa_cardiaca_ppg = nk.ppg_rate(picos_sistolicos[i], sampling_rate = 125)\n    heart_rate_PLETH.append(tasa_cardiaca_ppg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#A continuación, nos disponemos a calcular características del propio ECG.\n#bpm instantáneo\ntemplates_II = []\nbeats_II = []\ntemplates_V = []\nbeats_V = []\nfor i in range(len(lista_filtrada_II)):\n    templates, rpiks = biosppy.signals.ecg.extract_heartbeats(lista_filtrada_II[i], rpeaks_II[i], sampling_rate = 125)\n    templates_II.append(templates)\n    beats_II.append(rpiks)\nfor i in range(len(lista_filtrada_V)):\n    templates, rpiks = biosppy.signals.ecg.extract_heartbeats(lista_filtrada_V[i], rpeaks_V[i], sampling_rate = 125)\n    templates_V.append(templates)\n    beats_V.append(rpiks)\nheart_rate_inst_II = []\nheart_rate_inst_V = []\nfor i in range(len(beats_II)):\n    try:\n        index, heart_rate = biosppy.signals.tools.get_heart_rate(beats_II[i], sampling_rate = 125)\n        heart_rate_inst_II.append(heart_rate)\n    except ValueError: #Salta porque hay bradicardias probablemente\n        heart_rate_inst_II.append(50)\nfor i in range(len(beats_V)):\n    try:\n        index, heart_rate = biosppy.signals.tools.get_heart_rate(beats_V[i], sampling_rate = 125)\n        heart_rate_inst_V.append(heart_rate)\n    except ValueError: #Salta porque hay bradicardias probablemente\n        heart_rate_inst_II.append(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sacamos todos los onsets ,offsets y el resto de picos aparte de R que conforman PQRS\n#ecg_delineate()\ntpeaks_V = []\ntoffsets_V = []\nppeaks_V = []\nponsets_V = []\ntpeaks_II = []\ntoffsets_II = []\nppeaks_II = []\nponsets_II = []\nfor i in range(len(lista_filtrada_V)):\n    try:\n        proceso = nk.ecg_delineate (lista_filtrada_V[i], rpeaks = rpeaks_V, sampling_rate = 125, method = 'dwt') \n        tpeaks_V.append(proceso[0]['ECG_T_Peaks'])\n        toffsets_V.append(proceso[0]['ECG_T_Offsets'])\n        ppeaks_V.append(proceso[0]['ECG_P_Peaks'])\n        ponsets_V.append(proceso[0]['ECG_P_Onsets'])\n    except ValueError: #Taquicardia\n        tpeaks_V.append(0.0001)\n        toffsets_V.append(0.0001)\n        ppeaks_V.append(0.0001)\n        ponsets_V.append(0.0001)\n    except IndexError:\n        tpeaks_V.append(0.0001)\n        toffsets_V.append(0.0001)\n        ppeaks_V.append(0.0001)\n        ponsets_V.append(0.0001)\nfor i in range(len(lista_filtrada_V)):\n    try:\n        proceso = nk.ecg_delineate (lista_filtrada_II[i], rpeaks = rpeaks_V, sampling_rate = 125, method = 'dwt') \n        tpeaks_II.append(proceso[0]['ECG_T_Peaks'])\n        toffsets_II.append(proceso[0]['ECG_T_Offsets'])\n        ppeaks_II.append(proceso[0]['ECG_P_Peaks'])\n        ponsets_II.append(proceso[0]['ECG_P_Onsets'])\n    except ValueError:#Taquicardias\n        tpeaks_II.append(0.0001)\n        toffsets_II.append(0.0001)\n        ppeaks_II.append(0.0001)\n        ponsets_II.append(0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Seguimos obteniendo características del ECG, ahora en relación con la tasa de variación cardiaca\n\nrmssd_V = []\nrmssd_II = []\nmeanNN_V = []\nmeanNN_II = []\nsdNN_V = []\nsdNN_II = []\nsdsd_V = []\nsdsd_II = []\ncvNN_V = []\ncvNN_II = []\nCVSD_V = []\nCVSD_II = []\nmedianNN_V = [] \nmedianNN_II = []\nmadNN_V = []\nmadNN_II = []\nmcvNN_V = []\nmcvNN_II = []\npNN50_V = []\npNN50_II = []\npNN20_V = []\npNN20_II = []\nfor i in range(len(lista_filtrada_V)):\n    statistics = nk.hrv_time (rpeaks_V[i], sampling_rate = 125)\n    rmssd_V.append(statistics['HRV_RMSSD'][0])\n    meanNN_V.append(statistics['HRV_MeanNN'][0])\n    sdNN_V.append(statistics['HRV_SDNN'][0])\n    sdsd_V.append(statistics['HRV_SDSD'][0])\n    cvNN_V.append(statistics['HRV_CVNN'][0])\n    CVSD_V.append(statistics['HRV_CVSD'][0])\n    medianNN_V.append(statistics['HRV_MedianNN'][0])\n    madNN_V.append(statistics['HRV_MadNN'][0])\n    mcvNN_V.append(statistics['HRV_MCVNN'][0])\n    pNN50_V.append(statistics['HRV_pNN50'][0])\n    pNN20_V.append(statistics['HRV_pNN20'][0])\nfor i in range(len(lista_filtrada_II)):\n    statistics = nk.hrv_time (rpeaks_II[i], sampling_rate = 125)\n    rmssd_II.append(statistics['HRV_RMSSD'][0])\n    meanNN_II.append(statistics['HRV_MeanNN'][0])\n    sdNN_II.append(statistics['HRV_SDNN'][0])\n    sdsd_II.append(statistics['HRV_SDSD'][0])\n    cvNN_II.append(statistics['HRV_CVNN'][0])\n    CVSD_II.append(statistics['HRV_CVSD'][0])\n    medianNN_II.append(statistics['HRV_MedianNN'][0])\n    madNN_II.append(statistics['HRV_MadNN'][0])\n    mcvNN_II.append(statistics['HRV_MCVNN'][0])\n    pNN50_II.append(statistics['HRV_pNN50'][0])\n    pNN20_II.append(statistics['HRV_pNN20'][0])   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculamos parámetros frecuenciales (potencias en rangos de frecuencia)\nlf_V = []\nhf_V = []\nvhf_V = []\nlfn_V = [] #normalizada\nhfn_V = [] #normalizada\nratiolfhf_V = []\nlf_II = []\nhf_II = []\nvhf_II = []\nlfn_II = [] #normalizada\nhfn_II = [] #normalizada\nratiolfhf_II = []\nparam_frec = nk.hrv_frequency (rpeaks_V[40], sampling_rate = 125)\nfor i in range(len(lista_filtrada_V)):\n    try:\n        param_frec = nk.hrv_frequency (rpeaks_V[i], sampling_rate = 125)\n        lf_V.append(param_frec['HRV_LF'][0])\n        hf_V.append(param_frec['HRV_HF'][0])\n        vhf_V.append(param_frec['HRV_VHF'][0])\n        ratiolfhf_V.append(param_frec['HRV_LFHF'][0])\n        lfn_V.append(param_frec['HRV_LFn'][0])\n        hfn_V.append(param_frec['HRV_HFn'][0])\n    except IndexError: #Salta para aquellas muestras a las que previamente les habíamos \n         #asignado un 0 152, 162, 164, 322, 324, 384, 387, 389, 498, 508\n        lf_V.append(0.06)\n        hf_V.append(0.3)\n        vhf_V.append(0.45)\n        ratiolfhf_V.append(0.2)\n        lfn_V.append(0.2)\n        hfn_V.append(0.3)\n    except ValueError: #No salta para todas las anteriores pero sí para algunas que \n        #cumplen lo ya dicho, la 162\n        lf_V.append(0.06)\n        hf_V.append(0.3)\n        vhf_V.append(0.45)\n        ratiolfhf_V.append(0.2)\n        lfn_V.append(0.2)\n        hfn_V.append(0.3)\nfor i in range(len(lista_filtrada_II)):\n    try:\n        param_frec = nk.hrv_frequency (rpeaks_II[i], sampling_rate = 125)\n        lf_II.append(param_frec['HRV_LF'][0])\n        hf_II.append(param_frec['HRV_HF'][0])\n        vhf_II.append(param_frec['HRV_VHF'][0])\n        ratiolfhf_II.append(param_frec['HRV_LFHF'][0])\n        lfn_II.append(param_frec['HRV_LFn'][0])\n        hfn_II.append(param_frec['HRV_HFn'][0]) \n    except IndexError: #Salta para aquellas muestras a las que previamente les habíamos \n         #asignado un 0 152, 389\n        lf_II.append(0.06)\n        hf_II.append(0.3)\n        vhf_II.append(0.45)\n        ratiolfhf_II.append(0.2)\n        lfn_II.append(0.2)\n        hfn_II.append(0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculamos la calidad de la señal\nquality_V = []\nquality_II = []\n#152, 162, 164, 322, 324, 384, 387, 389, 498, 508\nfor i in range(len(lista_filtrada_V)):\n    try:\n        SQI = nk.ecg_quality(lista_filtrada_V[i], rpeaks_V[i], sampling_rate = 125)\n        quality_V.append(SQI[0])\n    except IndexError:\n        quality_V.append(0.7)\n    except ZeroDivisionError:\n        quality_V.append(0.7)\n    except ValueError:\n        quality_V.append(0.7)\nfor i in range(len(lista_filtrada_II)): #152, 389\n    try:\n        SQI = nk.ecg_quality(lista_filtrada_II[i], rpeaks_II[i], sampling_rate = 125) \n        quality_II.append(SQI[0])\n    except IndexError:\n        quality_II.append(0.7)\n    except ZeroDivisionError:\n        quality_II.append(0.7)\n    except ValueError:\n        quality_II.append(0.7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hrv_V = []\nhrv_SD1_V = []\nhrv_SD2_V = []\nhrv_SD1SD2_V = []\nhrv_S_V = []\nhrv_CSI_V = []\nhrv_CVI_V = []\nhrv_CSI_Modified_V = []\nhrv_GI_V = []\nhrv_SI_V = []\nhrv_AI_V = []\nhrv_PI_V = []\nhrv_SD1d_V = []\nhrv_SD1a_V = []\nhrv_C1d_V = []\nhrv_C1a_V = []\nhrv_SD2d_V = []\nhrv_SD2a_V = []\nhrv_C2d_V = []\nhrv_C2a_V = []\nhrv_SDNNd_V = []\nhrv_SDNNa_V = []\nhrv_Cd_V = []\nhrv_Ca_V = []\nhrv_PIP_V = []\nhrv_IALS_V = []\nhrv_PSS_V = []\nhrv_PAS_V = []\nhrv_ApEn_V = []\nhrv_SampEn_V = []\nhrv_II = []\nhrv_SD1_II = []\nhrv_SD2_II = []\nhrv_SD1SD2_II = []\nhrv_S_II = []\nhrv_CSI_II = []\nhrv_CVI_II = []\nhrv_CSI_Modified_II = []\nhrv_GI_II = []\nhrv_SI_II = []\nhrv_AI_II = []\nhrv_PI_II = []\nhrv_SD1d_II = []\nhrv_SD1a_II = []\nhrv_C1d_II = []\nhrv_C1a_II = []\nhrv_SD2d_II = []\nhrv_SD2a_II = []\nhrv_C2d_II = []\nhrv_C2a_II = []\nhrv_SDNNd_II = []\nhrv_SDNNa_II = []\nhrv_Cd_II = []\nhrv_Ca_II = []\nhrv_PIP_II = []\nhrv_IALS_II = []\nhrv_PSS_II = []\nhrv_PAS_II = []\nhrv_ApEn_II = []\nhrv_SampEn_II = []\nfor i in range(len(lista_filtrada_V)):\n    try:\n        hrv_V = nk.hrv_nonlinear(peaks = rpeaks_V[i] ,sampling_rate=125)\n        hrv_SD1_V.append(hrv['HRV_SD1'][0])\n        hrv_SD2_V.append(hrv['HRV_SD2'][0])\n        hrv_SD1SD2_V.append(hrv['HRV_SD1SD2'][0])\n        hrv_S_V.append(hrv['HRV_S'][0])\n        hrv_CSI_V.append(hrv['HRV_CSI'][0])\n        hrv_CVI_V.append(hrv['HRV_CVI'][0])\n        hrv_CSI_Modified_V.append(hrv['HRV_CSI_Modified'][0])\n        hrv_GI_V.append(hrv['HRV_GI'][0])\n        hrv_SI_V.append(hrv['HRV_SI'][0])\n        hrv_AI_V.append(hrv['HRV_AI'][0])\n        hrv_PI_V.append(hrv['HRV_PI'][0])\n        hrv_SD1d_V.append(hrv['HRV_SD1d'][0])\n        hrv_SD1a_V.append(hrv['HRV_SD1a'][0])\n        hrv_C1d_V .append(hrv['HRV_C1d'][0])\n        hrv_C1a_V.append(hrv['HRV_C1a'][0])\n        hrv_SD2d_V.append(hrv['HRV_SD2d'][0])\n        hrv_SD2a_V.append(hrv['HRV_SD2a'][0])\n        hrv_C2d_V.append(hrv['HRV_C2d'][0])\n        hrv_C2a_V.append(hrv['HRV_C2a'][0])\n        hrv_SDNNd_V.append(hrv['HRV_SDNNd'][0])\n        hrv_SDNNa_V.append(hrv['HRV_SDNNa'][0])\n        hrv_Cd_V.append(hrv['HRV_Cd'][0])\n        hrv_Ca_V.append(hrv['HRV_Ca'][0])\n        hrv_PIP_V.append(hrv['HRV_PIP'][0])\n        hrv_IALS_V.append(hrv['HRV_IALS'][0])\n        hrv_PSS_V.append(hrv['HRV_PSS'][0])\n        hrv_PAS_V.append(hrv['HRV_PAS'][0])\n        hrv_ApEn_V.append(hrv['HRV_ApEn'][0])\n        hrv_SampEn_V.append(hrv['HRV_SampEn'][0])\n    except: #ZeroDivisionError, ValueError\n        hrv_SD1_V.append(0.01)\n        hrv_SD2_V.append(0.01)\n        hrv_SD1SD2_V.append(0.01)\n        hrv_S_V.append(0.01)\n        hrv_CSI_V.append(0.01)\n        hrv_CVI_V.append(0.01)\n        hrv_CSI_Modified_V.append(0.01)\n        hrv_GI_V.append(0.01)\n        hrv_SI_V.append(0.01)\n        hrv_AI_V.append(0.01)\n        hrv_PI_V.append(0.01)\n        hrv_SD1d_V.append(0.01)\n        hrv_SD1a_V.append(0.01)\n        hrv_C1d_V .append(0.01)\n        hrv_C1a_V.append(0.01)\n        hrv_SD2d_V.append(0.01)\n        hrv_SD2a_V.append(0.01)\n        hrv_C2d_V.append(0.01)\n        hrv_C2a_V.append(0.01)\n        hrv_SDNNd_V.append(0.01)\n        hrv_SDNNa_V.append(0.01)\n        hrv_Cd_V.append(0.01)\n        hrv_Ca_V.append(0.01)\n        hrv_PIP_V.append(0.01)\n        hrv_IALS_V.append(0.01)\n        hrv_PSS_V.append(0.01)\n        hrv_PAS_V.append(0.01)\n        hrv_ApEn_V.append(0.01)\n        hrv_SampEn_V.append(0.01)\nfor i in range(len(lista_filtrada_II)):\n    try:\n        hrv_II = nk.hrv_nonlinear(peaks = rpeaks_II[i], sampling_rate = 125)\n        hrv_SD1_II.append(hrv['HRV_SD1'][0])\n        hrv_SD2_II.append(hrv['HRV_SD2'][0])\n        hrv_SD1SD2_II.append(hrv['HRV_SD1SD2'][0])\n        hrv_S_II.append(hrv['HRV_S'][0])\n        hrv_CSI_II.append(hrv['HRV_CSI'][0])\n        hrv_CVI_II.append(hrv['HRV_CVI'][0])\n        hrv_CSI_Modified_II.append(hrv['HRV_CSI_Modified'][0])\n        hrv_GI_II.append(hrv['HRV_GI'][0])\n        hrv_SI_II.append(hrv['HRV_SI'][0])\n        hrv_AI_II.append(hrv['HRV_AI'][0])\n        hrv_PI_II.append(hrv['HRV_PI'][0])\n        hrv_SD1d_II.append(hrv['HRV_SD1d'][0])\n        hrv_SD1a_II.append(hrv['HRV_SD1a'][0])\n        hrv_C1d_II.append(hrv['HRV_C1d'][0])\n        hrv_C1a_II.append(hrv['HRV_C1a'][0])\n        hrv_SD2d_II.append(hrv['HRV_SD2d'][0])\n        hrv_SD2a_II.append(hrv['HRV_SD2a'][0])\n        hrv_C2d_II.append(hrv['HRV_C2d'][0])\n        hrv_C2a_II.append(hrv['HRV_C2a'][0])\n        hrv_SDNNd_II.append(hrv['HRV_SDNNd'][0])\n        hrv_SDNNa_II.append(hrv['HRV_SDNNa'][0])\n        hrv_Cd_II.append(hrv['HRV_Cd'][0])\n        hrv_Ca_II.append(hrv['HRV_Ca'][0])\n        hrv_PIP_II.append(hrv['HRV_PIP'][0])\n        hrv_IALS_II.append(hrv['HRV_IALS'][0])\n        hrv_PSS_II.append(hrv['HRV_PSS'][0])\n        hrv_PAS_II.append(hrv['HRV_PAS'][0])\n        hrv_ApEn_II.append(hrv['HRV_ApEn'][0])\n        hrv_SampEn_II.append(hrv['HRV_SampEn'][0])\n    except: #ValueError, ZeroDivisionError\n        hrv_SD1_II.append(0.01)\n        hrv_SD2_II.append(0.01)\n        hrv_SD1SD2_II.append(0.01)\n        hrv_S_II.append(0.01)\n        hrv_CSI_II.append(0.01)\n        hrv_CVI_II.append(0.01)\n        hrv_CSI_Modified_II.append(0.01)\n        hrv_GI_II.append(0.01)\n        hrv_SI_II.append(0.01)\n        hrv_AI_II.append(0.01)\n        hrv_PI_II.append(0.01)\n        hrv_SD1d_II.append(0.01)\n        hrv_SD1a_II.append(0.01)\n        hrv_C1d_II.append(0.01)\n        hrv_C1a_II.append(0.01)\n        hrv_SD2d_II.append(0.01)\n        hrv_SD2a_II.append(0.01)\n        hrv_C2d_II.append(0.01)\n        hrv_C2a_II.append(0.01)\n        hrv_SDNNd_II.append(0.01)\n        hrv_SDNNa_II.append(0.01)\n        hrv_Cd_II.append(0.01)\n        hrv_Ca_II.append(0.01)\n        hrv_PIP_II.append(0.01)\n        hrv_IALS_II.append(0.01)\n        hrv_PSS_II.append(0.01)\n        hrv_PAS_II.append(0.01)\n        hrv_ApEn_II.append(0.01)\n        hrv_SampEn_II.append(0.01)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculamos rr intervals maximos y minimos\nmax_int_RR_II = []\nmax_int_RR_V = []\nfor i in range(len(rr_interval_V)):\n    elem = max(rr_interval_V[i])\n    max_int_RR_V.append(elem)\nfor i in range(len(rr_interval_II)):\n    elem = max(rr_interval_II[i])\n    max_int_RR_II.append(elem)\n#Calculamos estadisticos del heart rate\nmedia_hrV = []\nminimo_hrV = []\nmaximo_hrV = []\ndesviacion_hrV = []\nmedia_hrII = []\nminimo_hrII = []\nmaximo_hrII = []\ndesviacion_hrII = []\nfor i in range(len(rr_interval_V)):\n    try:\n        estadisticos_hr = pyhrv.time_domain.hr_parameters(nni = rr_interval_V[i])\n        media_hrV.append(estadisticos_hr[0])\n        minimo_hrV.append(estadisticos_hr[1])\n        maximo_hrV.append(estadisticos_hr[2])\n        desviacion_hrV.append(estadisticos_hr[3])\n    except: #152, 164, 322, 324, 384, 387, 389, 498, 508, IndexError, ValueError\n        media_hrV.append(45)\n        minimo_hrV.append(25)\n        maximo_hrV.append(51)\n        desviacion_hrV.append(2)\nfor i in range(len(rr_interval_II)):\n    try:\n        estadisticos_hr = pyhrv.time_domain.hr_parameters(nni = rr_interval_II[i])\n        media_hrII.append(estadisticos_hr[0])\n        minimo_hrII.append(estadisticos_hr[1])\n        maximo_hrII.append(estadisticos_hr[2])\n        desviacion_hrII.append(estadisticos_hr[3])\n    except ValueError:#153, 389\n        media_hrII.append(45)\n        minimo_hrII.append(25)\n        maximo_hrII.append(51)\n        desviacion_hrII.append(2)\n#Calculamos diferencias entre intervalos NN (picos R normalizados)\nmedia_nni_dif_II = []\nmin_nni_dif_II = []\nmax_nni_dif_II = []\nmedia_nni_dif_V = []\nmin_nni_dif_V = []\nmax_nni_dif_V = []\nfor i in range(len(rr_interval_V)):\n    try:\n        nni_differences = pyhrv.time_domain.nni_differences_parameters(nni = rr_interval_II[i][0])\n        media_nni_dif_V.append(nni_differences['nni_diff_mean'])\n        min_nni_dif_V.append(nni_differences['nni_diff_min'])\n        max_nni_dif_V.append(nni_differences['nni_diff_max'])\n    except IndexError:#152, 164, 322, 324, 384, 387, 389, 498, 508\n        media_nni_dif_V.append(282)\n        min_nni_dif_V.append(0)\n        max_hrV.append(1248)\n\n    except ValueError:#153, 389\n        media_nni_dif_V.append(282)\n        min_nni_dif_V.append(0)\n        max_nni_dif_V.append(1248)\n\nfor i in range(len(rr_interval_II)):\n    try:\n        nni_differences = pyhrv.time_domain.nni_differences_parameters(nni = rr_interval_II[i][0])\n        media_nni_dif_II.append(nni_differences['nni_diff_mean'])\n        min_nni_dif_II.append(nni_differences['nni_diff_min'])\n        max_nni_dif_II.append(nni_differences['nni_diff_max'])\n    except ValueError:#153, 389\n        media_nni_dif_II.append(282)\n        min_nni_dif_II.append(0)\n        max_nni_dif_II.append(1248)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, clear_output\nindex = []\nfor i in range(len(lista_filtrada_II)):\n    index.append(i)\nd = {'index': index, 'col1': media_hrII, 'col2': desviacion_hrII}\nX = pd.DataFrame(data = d) \nX = np.array(X)\nprint(X.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, clear_output\nindex = []\nfor i in range(len(lista_filtrada_II)):\n    index.append(i)\nd = {'index': index, 'col1': media_hrII, 'col2': desviacion_hrII, 'col3': hrv_SD1SD2_II, \n    'col4' : hrv_SD1SD2_V, 'col5': media_hrV, 'col6': desviacion_hrV, 'col7': hrv_SampEn_II, \n    'col8': hrv_SampEn_V}\nX = pd.DataFrame(data = d) \nX = np.array(X)\nprint(X.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get labels for the patients\ny = np.loadtxt('/kaggle/input/physiological-signals-processing-challenge-2021/alarms_training.csv',skiprows=1,delimiter = ',',usecols = [0,1])\n\ny_train = y[np.array(X[:,0]-1,dtype = int),:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create naive bayes\nfrom sklearn.naive_bayes import GaussianNB\n\n#get priors\n\nP_h0 = np.mean(y_train[:,1] == 0)\nP_h1 = np.mean(y_train[:,1] == 1)\n\nprint('P_h0:',P_h0,'; P_h1:',P_h1)\n\n#naive bayes model\n\nnb_detector = GaussianNB(priors = [P_h0,P_h1])\n\n#train the model\nnb_detector.fit(X[:,1:],y_train[:,1])\n\nprint(\"mean values n_classes, n_features\")\nprint(nb_detector.theta_)\n\nprint(\"variance values n_classes, n_features\")\nprint(nb_detector.sigma_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict first case\n\nx_1 = X[0,1:]\n\nD = nb_detector.predict(x_1[np.newaxis,:])\n\nprint(X[0,0])\nprint(y_train[0,0])\nprint('Detection: %d'%D[0])\nprint('Hypothesis H: %d' %y_train[0,1])\n\n#whole training set\ny_hat = nb_detector.predict(X[:,1:])\n\n\nprint('ACC = %.2f'%np.mean(y_hat == y_train[:,1]))\nfrom sklearn.metrics import f1_score\nprint('f1 =', f1_score(y_train[:, 1], y_hat))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  \n\nX_test = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input/physiological-signals-processing-challenge-2021/data_challenge/test/'):\n    filenames.sort()\n    j = 0\n    for filename in filenames:\n        #print(filename)\n        \n        if j%25==0:\n            clear_output(wait = True)\n            print(j,\" of \",len(filenames)/2)\n            #print(filename)\n            \n        if 'mat' in filename:\n            continue\n        #\n        j+=1\n        #read the pat data\n        record = loadmat(os.path.join(dirname,filename[:-4]+'.mat'))\n        \n        #get the header\n        with open(os.path.join(dirname,filename)) as f:\n                header = f.readlines()\n\n        #pass to the function to get the mean and std heart rate\n        \n        mean_hr,std_hr = get_mean_std_hr_one_pat(record,header,plot_flag = False)\n        \n        X_test.append([int(filename[:-4]),mean_hr,std_hr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sort data\nX_test = np.array(X_test)\nprint(X_test[:3,:])\nidx_sort = np.argsort(X_test[:,0])\n\nX_test = X_test[idx_sort,:]\n\nprint(X_test[:3,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict\n\ny_hat_test = nb_detector.predict(X_test[:,1:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_hat_test[:])\n\n#create solution\n\nimport pandas as pd\n\ndf = pd.DataFrame({'Id': X_test[:,0], 'Category': y_hat_test})\n\ndf.to_csv('submission_naive_bayes.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}